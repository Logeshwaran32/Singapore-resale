{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1BTyUqvPJ8Ybg4acNZeQnZk7zgCfWtcmJ",
      "authorship_tag": "ABX9TyNqkHLMCEWjU+yC/qWgABHy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Logeshwaran32/Singapore-resale/blob/main/Singapore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zfvuT2fpYXtE"
      },
      "outputs": [],
      "source": [
        "#!pip install numpy\n",
        "#!pip install pandas\n",
        "#!pip install matplotlib\n",
        "#!pip install scikit-learn\n",
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "import statsmodels.api as sm\n",
        "from wordcloud import WordCloud\n",
        "import plotly.express as px\n",
        "import joblib\n",
        "import matplotlib.patches as mpatches\n",
        "import plotly.graph_objects as go\n",
        "import calendar\n",
        "import streamlit as st\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "FX5RJzaXYlH0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   Data Preprocessing and cleaning\n",
        "2.   Reading all the datasets for a basic understanding\n",
        "\n"
      ],
      "metadata": {
        "id": "WVXfVs6LWHb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file into dataframe\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/DataSet/Singapore_resale_flat_prices_01.csv\")\n",
        "\n",
        "# Print the basic information and first few rows of the dataframe\n",
        "print(df1.info())\n",
        "print(df1.head())"
      ],
      "metadata": {
        "id": "CAd_0DO1YsQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file into dataframe\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/DataSet/Singapore_resale_flat_prices_02.csv\")\n",
        "\n",
        "# Print the basic information and first few rows of the dataframe\n",
        "print(df2.info())\n",
        "print(df2.head())"
      ],
      "metadata": {
        "id": "P09_hcQaYwhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file into dataframe\n",
        "df3 = pd.read_csv(\"/content/drive/MyDrive/DataSet/Singapore_resale_flat_prices_03.csv\")\n",
        "\n",
        "# Print the basic information and first few rows of the dataframe\n",
        "print(df3.info())\n",
        "print(df3.head())"
      ],
      "metadata": {
        "id": "ct5LnYqMY-3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file into dataframe\n",
        "df4 = pd.read_csv(\"/content/drive/MyDrive/DataSet/Singapore_resale_flat_prices_04.csv\")\n",
        "\n",
        "# Print the basic information and first few rows of the dataframe\n",
        "print(df4.info())\n",
        "print(df4.head())"
      ],
      "metadata": {
        "id": "BALSYZzSZCfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the csv file into dataframe\n",
        "df5 = pd.read_csv(\"/content/drive/MyDrive/DataSet/Singapore_resale_flat_prices_05.csv\")\n",
        "\n",
        "# Print the basic information and first few rows of the dataframe\n",
        "print(df5.info())\n",
        "print(df5.head())"
      ],
      "metadata": {
        "id": "n5D-imbZZRKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the numerical part of the remaining lease from DF5"
      ],
      "metadata": {
        "id": "9praOFxsWXhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the numeric part of 'remaining_lease', split by space, and convert to integer\n",
        "df5['remaining_lease'] = df5['remaining_lease'].str.split(' ').str[0].astype('int64')\n",
        "\n",
        "# Display the updated 'remaining_lease' column\n",
        "print(df5['remaining_lease'])\n",
        "\n",
        "# Print the basic information and first few rows of the dataframe\n",
        "print(df5.info())\n",
        "print(df5.head())"
      ],
      "metadata": {
        "id": "mb6PapO3ZUPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging all the datasets"
      ],
      "metadata": {
        "id": "rzPt2HB5YE5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging datasets df1, df2, df3, df4 and df5\n",
        "df_combined = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
        "\n",
        "# Print the basic information and first few rows of the merged dataframe\n",
        "print(df_combined.info())\n",
        "print(df_combined.head())"
      ],
      "metadata": {
        "id": "YpmmfgpAZWte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the month column to month and year"
      ],
      "metadata": {
        "id": "f9j4NhqtYMHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split 'month' into 'year' and 'month' columns\n",
        "df_combined[['year', 'month']] = df_combined['month'].str.split('-', expand=True)\n",
        "\n",
        "# Convert 'year' and 'month' columns to numeric types if needed\n",
        "df_combined['year'] = pd.to_numeric(df_combined['year'])\n",
        "df_combined['month'] = pd.to_numeric(df_combined['month'])\n",
        "\n",
        "# Display the basic information and the updated DataFrame\n",
        "print(df_combined.info())\n",
        "print(df_combined.head())"
      ],
      "metadata": {
        "id": "3BQRLZjlYLZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the remaining lease for the Nan values"
      ],
      "metadata": {
        "id": "89f8YWPkYawo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate remaining lease for rows with NaN values\n",
        "df_combined['remaining_lease'].fillna(99 - (df_combined['year'] - df_combined['lease_commence_date']), inplace=True)\n",
        "\n",
        "# Verify the results\n",
        "print(df_combined[['lease_commence_date', 'year', 'remaining_lease']])"
      ],
      "metadata": {
        "id": "8ZrmexxIZaPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for repetitions in categorical columns"
      ],
      "metadata": {
        "id": "d8zlsFHmYo7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing unique values of the categorical columns to check for repetitions\n",
        "print(df_combined['town'].unique())\n",
        "print(df_combined['flat_type'].unique())\n",
        "print(df_combined['block'].unique())\n",
        "print(df_combined['street_name'].unique())\n",
        "print(df_combined['storey_range'].unique())\n",
        "print(df_combined['flat_model'].unique())"
      ],
      "metadata": {
        "id": "zllci4btafto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the case to uppercase for consistency\n",
        "df_combined['flat_model'] = df_combined['flat_model'].str.upper()\n",
        "\n",
        "# Printing the unique values\n",
        "print(df_combined['flat_model'].unique())"
      ],
      "metadata": {
        "id": "H9ZfVhKhaimi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'flat_type' values to lowercase\n",
        "df_combined['flat_type'] = df_combined['flat_type'].str.lower()\n",
        "\n",
        "# Standardize values to a common set of categories\n",
        "type_mapping = {\n",
        "    '1 room': '1 room',\n",
        "    '3 room': '3 room',\n",
        "    '4 room': '4 room',\n",
        "    '5 room': '5 room',\n",
        "    '2 room': '2 room',\n",
        "    'executive': 'executive',\n",
        "    'multi generation': 'multi generation',\n",
        "    'multi-generation': 'multi generation'\n",
        "}\n",
        "\n",
        "df_combined['flat_type'] = df_combined['flat_type'].map(type_mapping)\n",
        "\n",
        "# Changing the case to Uppercase\n",
        "df_combined['flat_type'] = df_combined['flat_type'].str.upper()\n",
        "\n",
        "# Display the unique values\n",
        "print(df_combined['flat_type'].unique())"
      ],
      "metadata": {
        "id": "UaRkUw0daoYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the outliers in the columns 'remaining_lease' and 'storey_range'"
      ],
      "metadata": {
        "id": "TNo7WeXTZN4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for number of rows with remaining lease period more than 99\n",
        "print((df_combined['remaining_lease']>99).sum())\n",
        "\n",
        "# Create a boolean mask to identify rows containing any of the specified values\n",
        "mask = df_combined['remaining_lease']>99\n",
        "\n",
        "# Use the boolean mask to drop rows\n",
        "df_combined = df_combined[~mask]\n",
        "\n",
        "# Display the DataFrame after dropping rows\n",
        "print(df_combined)"
      ],
      "metadata": {
        "id": "36hrcB1matD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where the 'storey_range' column contains specific values\n",
        "values_to_drop = ['01 TO 05', '06 TO 10', '11 TO 15', '16 TO 20', '21 TO 25', '26 TO 30', '31 TO 35', '36 TO 40']\n",
        "\n",
        "# Create a boolean mask to identify rows containing any of the specified values\n",
        "mask = df_combined['storey_range'].isin(values_to_drop)\n",
        "\n",
        "# Use the boolean mask to drop rows\n",
        "df_combined = df_combined[~mask]\n",
        "\n",
        "# Display the DataFrame after dropping rows\n",
        "print(df_combined)"
      ],
      "metadata": {
        "id": "GRaHMWRfazdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Storey range to lower bound and upper bound"
      ],
      "metadata": {
        "id": "zlUzSftEZzes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the 'storey_range' into lower and upper bounds\n",
        "df_combined[['lower_bound', 'upper_bound']] = df_combined['storey_range'].str.split(' TO ', expand=True)\n",
        "\n",
        "# Convert the lower and upper bounds to numeric values\n",
        "df_combined['lower_bound'] = pd.to_numeric(df_combined['lower_bound'])\n",
        "df_combined['upper_bound'] = pd.to_numeric(df_combined['upper_bound'])\n",
        "\n",
        "# Display the DataFrame with lower and upper bounds\n",
        "print(df_combined[['storey_range', 'lower_bound', 'upper_bound']])"
      ],
      "metadata": {
        "id": "9BRX8aiha2CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column 'price_per_sqm'\n",
        "df_combined['price_per_sqm'] = df_combined['resale_price'] / df_combined['floor_area_sqm']\n",
        "\n",
        "# Adding a new column 'years_holding'\n",
        "df_combined['years_holding'] = df_combined['year'] - df_combined['lease_commence_date']\n",
        "\n",
        "# Adding a new column 'current_remaining_lease'\n",
        "df_combined['current_remaining_lease'] = df_combined['remaining_lease'] - (2024 - df_combined['year'])\n",
        "\n",
        "# Display the DataFrame with the new column\n",
        "print(df_combined[['resale_price', 'floor_area_sqm', 'price_per_sqm']])\n",
        "print(df_combined[['year', 'lease_commence_date', 'remaining_lease', 'years_holding', 'current_remaining_lease']])"
      ],
      "metadata": {
        "id": "E0_e1SxhbGyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the clean dataset to a file\n",
        "df_combined = df_combined.reset_index(drop=True)\n",
        "df_combined.to_csv('/content/drive/MyDrive/DataSet/Singapore_resale_flat_prices_updated.csv', index=False)"
      ],
      "metadata": {
        "id": "psu3wGohbL9c"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Exploratory Data Analysis\n",
        "*   Displaying basic statistics of the columns\n",
        "\n"
      ],
      "metadata": {
        "id": "uyWfAn2wafwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/DataSet/Singapore_resale_flat_prices_updated.csv')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(df.info())\n",
        "\n",
        "# Display summary statistics of numerical columns\n",
        "print(df.describe())\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "AL2ch_TZbPZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Univariate Analysis"
      ],
      "metadata": {
        "id": "J5YKTUh9a3hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df['resale_price'], bins=20, kde=True)\n",
        "plt.title('Histogram: Resale Price')\n",
        "plt.xlabel('Resale Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Box Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=df['month'])\n",
        "plt.title('Box Plot: Month of Sale')\n",
        "plt.xlabel('Month of Sale')\n",
        "plt.show()\n",
        "\n",
        "# Bar Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='lease_commence_date', data=df)\n",
        "plt.title('Bar Plot: Date of lease commencement')\n",
        "plt.xlabel('Date of lease commencement')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZIfLViUobVVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot\n",
        "sns.scatterplot(x='year', y='price_per_sqm', data=df)\n",
        "plt.title('Scatter Plot: Price per square meter vs Year')\n",
        "plt.show()\n",
        "\n",
        "# Line plot\n",
        "sns.lineplot(x='flat_model', y='price_per_sqm', data=df)\n",
        "plt.title('Line Plot: Flat Model vs Price per square meter')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# Heatmap\n",
        "sns.heatmap(df[['price_per_sqm', 'lease_commence_date']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Heatmap: Correlation between Price per square meter and Lease commencement year')\n",
        "plt.show()\n",
        "\n",
        "# Bubble plot\n",
        "sns.scatterplot(x='remaining_lease', y='price_per_sqm', size='floor_area_sqm', data=df)\n",
        "plt.title('Bubble Plot: Price per square meter vs Remaining lease with floor_area_sqm as size')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "po5yAKFMbYvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect aberrant or missing values"
      ],
      "metadata": {
        "id": "T90ya_vFb_6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing Values:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Detect outliers using Z-score\n",
        "z_scores = zscore(df[['resale_price', 'floor_area_sqm']])\n",
        "outliers = (abs(z_scores) > 3).all(axis=1)\n",
        "print(\"Number of outliers:\", outliers.sum())"
      ],
      "metadata": {
        "id": "gbsKkIBQbdh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap\n",
        "sns.heatmap(df[['resale_price', 'year', 'lease_commence_date', 'remaining_lease']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Heatmap: Correlation between Resale price and other variables')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4SddxSajbfqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping the flats sold by month and flat model\n",
        "total_units_by_month_flat_model = df.groupby(['month', 'flat_model']).size().reset_index(name='total_units')\n",
        "\n",
        "# Convert month integers to month names\n",
        "total_units_by_month_flat_model['month'] = total_units_by_month_flat_model['month'].apply(lambda x: calendar.month_abbr[x])\n",
        "\n",
        "fig = px.line_polar(total_units_by_month_flat_model, r=\"total_units\", theta=\"month\", color=\"flat_model\", line_close=True,\n",
        "                    color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
        "                    template=\"plotly_dark\",)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "JTiCHejObl_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping the flats sold by month and Year\n",
        "total_units_by_month_year = df.groupby(['month', 'year']).size().reset_index(name='total_units')\n",
        "\n",
        "# Convert month integers to month names\n",
        "total_units_by_month_year['month'] = total_units_by_month_year['month'].apply(lambda x: calendar.month_abbr[x])\n",
        "\n",
        "fig = px.line_polar(total_units_by_month_year, r=\"total_units\", theta=\"month\", color=\"year\", line_close=True,\n",
        "                    color_discrete_sequence=px.colors.sequential.Plasma_r\n",
        "                    )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wX1Tj-vWboW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   Model Building and evaluation\n",
        "2.   Linear Regression"
      ],
      "metadata": {
        "id": "e57BcfaHcqWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant columns\n",
        "selected_columns = ['year', 'town', 'flat_type', 'flat_model', 'storey_range',\n",
        "                    'floor_area_sqm', 'lease_commence_date', 'remaining_lease',\n",
        "                    'current_remaining_lease', 'years_holding', 'resale_price']\n",
        "dftrain = df[selected_columns]\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = dftrain.drop('resale_price', axis=1)\n",
        "y = dftrain['resale_price']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing for numerical and categorical features\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create transformers\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder()\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create the regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Create and evaluate the pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                             ('model', model)])\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# save the model\n",
        "model_filename = 'resale_price_prediction_linear.joblib'\n",
        "joblib.dump(pipeline, model_filename)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Print or use the metrics as needed\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R-squared (R2) Score: {r2}\")\n",
        "print(f\"Explained Variance Score: {explained_variance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TolWUpO6c0BU",
        "outputId": "b958accd-689a-4845-ef97-54a4435c383f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 51686.23904678422\n",
            "Mean Squared Error (MSE): 4570029691.474099\n",
            "Root Mean Squared Error (RMSE): 67601.99472999372\n",
            "R-squared (R2) Score: 0.835739586225564\n",
            "Explained Variance Score: 0.8357404630864257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision trees"
      ],
      "metadata": {
        "id": "-OqkcHbIc8sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant columns\n",
        "selected_columns = ['year', 'town', 'flat_type', 'flat_model', 'storey_range',\n",
        "                    'floor_area_sqm', 'lease_commence_date', 'remaining_lease',\n",
        "                    'current_remaining_lease', 'years_holding', 'resale_price']\n",
        "dftrain = df[selected_columns]\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = dftrain.drop('resale_price', axis=1)\n",
        "y = dftrain['resale_price']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing for numerical and categorical features\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create transformers\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder()\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create the regression model\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Create and evaluate the pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                             ('model', model)])\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# save the model\n",
        "model_filename = 'resale_price_prediction_decision_tree.joblib'\n",
        "joblib.dump(pipeline, model_filename)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Print or use the metrics as needed\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R-squared (R2) Score: {r2}\")\n",
        "print(f\"Explained Variance Score: {explained_variance}\")"
      ],
      "metadata": {
        "id": "bZB5K8bcc942"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant columns\n",
        "selected_columns = ['year', 'town', 'flat_type', 'flat_model', 'storey_range',\n",
        "                    'floor_area_sqm', 'lease_commence_date', 'remaining_lease',\n",
        "                    'current_remaining_lease', 'years_holding', 'resale_price']\n",
        "dftrain = df[selected_columns]\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = dftrain.drop('resale_price', axis=1)\n",
        "y = dftrain['resale_price']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing for numerical and categorical features\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create transformers\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder()\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create the regression model\n",
        "model = KNeighborsRegressor()\n",
        "\n",
        "# Create and evaluate the pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                             ('model', model)])\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# save the model\n",
        "model_filename = 'resale_price_prediction_knn.joblib'\n",
        "joblib.dump(pipeline, model_filename)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Print or use the metrics as needed\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R-squared (R2) Score: {r2}\")\n",
        "print(f\"Explained Variance Score: {explained_variance}\")"
      ],
      "metadata": {
        "id": "vqzjYeradMq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "explained_variance = explained_variance_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rmmafYr8d0Vz",
        "outputId": "39c7f097-a7ba-4c75-9aed-8b323ba658f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pipeline' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b579105a10b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9BFBjFKJkuWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit"
      ],
      "metadata": {
        "id": "sOLShNGYb131"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import streamlit as st\n",
        "import joblib\n",
        "\n",
        "# Define unique values for select boxes\n",
        "flat_model_options = ['IMPROVED', 'NEW GENERATION', 'MODEL A', 'STANDARD', 'SIMPLIFIED',\n",
        "                      'MODEL A-MAISONETTE', 'APARTMENT', 'MAISONETTE', 'TERRACE', '2-ROOM',\n",
        "                      'IMPROVED-MAISONETTE', 'MULTI GENERATION', 'PREMIUM APARTMENT',\n",
        "                      'ADJOINED FLAT', 'PREMIUM MAISONETTE', 'MODEL A2', 'DBSS', 'TYPE S1',\n",
        "                      'TYPE S2', 'PREMIUM APARTMENT LOFT', '3GEN']\n",
        "flat_type_options = ['1 ROOM', '3 ROOM', '4 ROOM', '5 ROOM', '2 ROOM', 'EXECUTIVE', 'MULTI GENERATION']\n",
        "town_options = ['ANG MO KIO', 'BEDOK', 'BISHAN', 'BUKIT BATOK', 'BUKIT MERAH', 'BUKIT TIMAH',\n",
        "                'CENTRAL AREA', 'CHOA CHU KANG', 'CLEMENTI', 'GEYLANG', 'HOUGANG',\n",
        "                'JURONG EAST', 'JURONG WEST', 'KALLANG/WHAMPOA', 'MARINE PARADE',\n",
        "                'QUEENSTOWN', 'SENGKANG', 'SERANGOON', 'TAMPINES', 'TOA PAYOH', 'WOODLANDS',\n",
        "                'YISHUN', 'LIM CHU KANG', 'SEMBAWANG', 'BUKIT PANJANG', 'PASIR RIS', 'PUNGGOL']\n",
        "storey_range_options = ['10 TO 12', '04 TO 06', '07 TO 09', '01 TO 03', '13 TO 15', '19 TO 21',\n",
        "                        '16 TO 18', '25 TO 27', '22 TO 24', '28 TO 30', '31 TO 33', '40 TO 42',\n",
        "                        '37 TO 39', '34 TO 36', '46 TO 48', '43 TO 45', '49 TO 51']\n",
        "\n",
        "\n",
        "# Load the saved model\n",
        "model_filename = r'resale_price_prediction_decision_tree.joblib'\n",
        "pipeline = joblib.load(model_filename)\n",
        "\n",
        "# Streamlit app title\n",
        "st.title(\"Resale Price Prediction App\")\n",
        "\n",
        "# Create a Streamlit sidebar with input fields\n",
        "st.sidebar.title(\"Flat Details\")\n",
        "town = st.sidebar.selectbox(\"Town\", options=town_options)\n",
        "flat_type = st.sidebar.selectbox(\"Flat Type\", options=flat_type_options)\n",
        "flat_model = st.sidebar.selectbox(\"Flat Model\", options=flat_model_options)\n",
        "storey_range = st.sidebar.selectbox(\"Storey Range\", options=storey_range_options)\n",
        "floor_area_sqm = st.sidebar.number_input(\"Floor Area (sqm)\", min_value=0.0, max_value=500.0, value=100.0)\n",
        "current_remaining_lease = st.sidebar.number_input(\"Current Remaining Lease\", min_value=0.0, max_value=99.0, value=20.0)\n",
        "year = 2024\n",
        "lease_commence_date = current_remaining_lease + year - 99\n",
        "years_holding = 99 - current_remaining_lease\n",
        "\n",
        "# Create a button to trigger the prediction\n",
        "if st.sidebar.button(\"Predict Resale Price\"):\n",
        "    # Prepare input data for prediction\n",
        "    input_data = pd.DataFrame({\n",
        "        'town': [town],\n",
        "        'flat_type': [flat_type],\n",
        "        'flat_model': [flat_model],\n",
        "        'storey_range': [storey_range],\n",
        "        'floor_area_sqm': [floor_area_sqm],\n",
        "        'current_remaining_lease': [current_remaining_lease],\n",
        "        'lease_commence_date': [lease_commence_date],\n",
        "        'years_holding': [years_holding],\n",
        "        'remaining_lease': [current_remaining_lease],\n",
        "        'year': [year]\n",
        "    })\n",
        "\n",
        "    # Make a prediction using the model\n",
        "    prediction = pipeline.predict(input_data)\n",
        "\n",
        "    # Display the prediction\n",
        "    st.write(\"Predicted Resale Price:\", prediction)"
      ],
      "metadata": {
        "id": "GnR5z8MTb3gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart Streamlit app\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "65BxJ5r5dus0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2bthDyyaiMiZYDL2k8MDnRD8GGs_6tghXCdi23Y49kGT8hSgc"
      ],
      "metadata": {
        "id": "4UZuQc2pdyR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print(public_url)"
      ],
      "metadata": {
        "id": "ibNkq63pd1WW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}